#!/usr/bin/env python
#coding=utf-8
from numpy import fromfile
from nltk.util import ngrams
from sklearn.metrics.pairwise import cosine_similarity
from morfeusz2 import Morfeusz
from os import listdir, remove
import re
import codecs
import xml.etree.ElementTree as ET
from sys import argv, exit
#other imports

corpus_filename = 'pl.txt'
try:
	filename = argv[1]
	if filename in listdir('.'):
		corpus_filename = filename
	else:
		print ('File %s not found in the current directory' % filename)
		exit(-1)
except IndexError:
	pass

synsets = None
def extract_corpus_part(filename):
	synsets = []
	#with open(filename,  mode='r') as f: # encoding='utf-8',
	with codecs.open(filename, encoding='utf-8', mode='r') as f: # encoding='utf-8',
		f.readline()
		#f.readline()	
		for line in f:
			sentence = []
			try:
				syns = ET.fromstring(line.encode('utf-8'))
				for word in syns.iter('LITERAL'):
					sentence.append(unicode(word.text))
				if len(sentence) > 1:
					synsets.append(sentence)
			except ET.ParseError:
				print 'xml.etree.ElementTree.ParseError!!!'
				pass
	print 'len(synsets): ', len(synsets)
	return synsets

def get_syns(word):
	word_u = unicode(word.decode('utf8'))
	for synset in synsets:
		for term in synset:
			if term == word_u:
				return synset

synsets = extract_corpus_part("plwordnet-3.0-visdisc.xml")

max_n = 3
morph = Morfeusz()
	
#load data

def get_form_similarity(form, form_test):
	similarity = 0
	l = min(len(form), len(form_test))
	for n_feature in xrange(0, l):
		if form[n_feature] == form_test[n_feature]:
			similarity += 1
	return similarity / l

def find_syns(word, form):
	syns_in_form = []
	syns = get_syns(word) # vector of synonyms
	if syns is None:
		return
	syns.remove(word)
	for i in xrange(0, len(syns)):
		if len(syns[i].split()) > 1:
			continue
		full_desc = morph.generate(syns[i])
		if 'ign' == full_desc[0][2]: # if morph does not contain the word
			continue
		form_similarities = []
		for form_test in full_desc:
			form_similarities.append(get_form_similarity(form, form_test))
		index_of_best_form = form_similarities.index(max(form_similarities))
		syns_in_form.append(full_desc[index_of_best_form][0])
	#print syns
	return syns		

# remove previous result
if 'generated_with_wn.txt' in listdir('.'):
		remove('generated_with_wn.txt')
		
f = codecs.open(corpus_filename, encoding='utf-8')

# main cycle
for raw_line in f:
	sentence = re.split('\W+', raw_line.lower(), flags=re.UNICODE)
	ngrams2file = []
	for ngram_tuple in ngrams(sentence, min(len(sentence[:-1]), max_n)): # [:-1] because sentence has empty word as the last element
		ngram = list(ngram_tuple)
		ngrams2file.append(ngram) # initial form of ngram
		for c in xrange(0, len(ngram)):	# step by word in ngram
			w_desc = morph.analyse(ngram[c])
			if len(w_desc) > 0:
				init_form = w_desc[0][2][1].split(':')[0]
				#print 'init_form: ', type(init_form)
				try:
					 #index = dictionary.index(init_form) # + u'\n'
					 #print 'index: ', index
					 syns = find_syns(init_form, w_desc[0][2][2].split(':'))
					 if syns is None:
						break
					 #print 'syns: '
					 for syn in syns:
					 	ngram2file = ngram[:]
					 	#print(syn)
						ngram2file[c] = syn
						ngrams2file.append(ngram2file) #u' '.join(ngram2file)
						#print 'n ', ngrams2file[-1]
				except ValueError:
					#print 'Word not in dictionary'
					continue
	generated = open('generated_with_wn.txt', mode='a')
	for ngram2file2 in ngrams2file:
		generated.write(u' '.join(ngram2file2).encode('utf8') + '\n')
	generated.close()
f.close()

